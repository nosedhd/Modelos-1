{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za9ElGRUAk_j",
        "outputId": "52040ad9-d106-4ec9-edb1-b63fd7148f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aclaración\n",
        "\n",
        "\n",
        "La organización de carpetas y la descompresión se hizo de manera manual, lo unico que se mantuvo en codigo fue la descarga de la primera celda. Se pretende poner los notebooks en una carpeta anterior a la carpeta que se geenera despues de descomprimir la descarga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPOJDc71SN3L"
      },
      "source": [
        "# Data Cleaning alterno\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalizar_programa(texto):\n",
        "    if not isinstance(texto, str):\n",
        "        return 'OTROS'\n",
        "\n",
        "    texto = texto.lower()\n",
        "    palabras_clave = {\n",
        "        'admin': 'ADMINISTRACION',\n",
        "        'contad': 'CONTADURIA',\n",
        "        'ingenier': 'INGENIERIA',\n",
        "        'medic': 'MEDICINA',\n",
        "        'psicolog': 'PSICOLOGIA',\n",
        "        'derech': 'DERECHO',\n",
        "        'enfermer': 'ENFERMERIA',\n",
        "        'econom': 'ECONOMIA',\n",
        "        'arquitect': 'ARQUITECTURA'\n",
        "    }\n",
        "\n",
        "    for key, value in palabras_clave.items():\n",
        "        if key in texto:\n",
        "            return value\n",
        "\n",
        "    return 'OTROS'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def preprocess_data(df, is_test=False):\n",
        "\n",
        "\n",
        "    # --- 1. Eliminación de columnas redundantes ---\n",
        "    df = df.drop(['FAMI_TIENEINTERNET.1', 'ESTU_PRIVADO_LIBERTAD'], axis=1, errors='ignore')\n",
        "\n",
        "    # --- 2. Conversión de variables booleanas con manejo de nulos mejorado ---\n",
        "    bool_map = {'Si': 1, 'No': 0}\n",
        "    bool_cols = ['FAMI_TIENEINTERNET', 'ESTU_PAGOMATRICULAPROPIO',\n",
        "             'FAMI_TIENECOMPUTADOR']\n",
        "\n",
        "    # Convertir a numérico y mantener nulos\n",
        "    for col in bool_cols:\n",
        "        df[col] = df[col].map(bool_map)\n",
        "\n",
        "    # --- 3. Procesamiento de estrato socioeconómico ---\n",
        "    # Extraer números de estrato y convertir a float\n",
        "    df['FAMI_ESTRATOVIVIENDA'] = (\n",
        "        df['FAMI_ESTRATOVIVIENDA']\n",
        "        .str.extract(r'(\\d+)')\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "    # Imputar con mediana (más robusto que moda)\n",
        "    median_estrato = df['FAMI_ESTRATOVIVIENDA'].median()\n",
        "    df['FAMI_ESTRATOVIVIENDA'] = df['FAMI_ESTRATOVIVIENDA'].fillna(median_estrato)\n",
        "\n",
        "    # Crear feature binaria para estratos bajos\n",
        "    df['ESTRATO_BAJO'] = (df['FAMI_ESTRATOVIVIENDA'] <= 2).astype(int)\n",
        "\n",
        "    # --- 4. Manejo de educación padres ---\n",
        "    edu_mapping = {\n",
        "        'Ninguno': 0,\n",
        "        'No sabe': 0,\n",
        "        'Primaria incompleta': 1,\n",
        "        'Primaria completa': 2,\n",
        "        'Secundaria (Bachillerato) incompleta': 3,\n",
        "        'Secundaria (Bachillerato) completa': 4,\n",
        "        'Técnica o tecnológica incompleta': 4.5,\n",
        "        'Técnica o tecnológica completa': 5,\n",
        "        'Universitaria incompleta': 5.5,\n",
        "        'Universitaria completa': 6,\n",
        "        'Postgrado': 7\n",
        "    }\n",
        "\n",
        "    df['EDUCACION_PADRE'] = df['FAMI_EDUCACIONPADRE'].map(edu_mapping).fillna(0)\n",
        "    df['EDUCACION_MADRE'] = df['FAMI_EDUCACIONMADRE'].map(edu_mapping).fillna(0)\n",
        "\n",
        "    # Crear característica combinada\n",
        "    df['EDUCACION_PADRES'] = (df['EDUCACION_PADRE'] + df['EDUCACION_MADRE']) / 2\n",
        "\n",
        "    # --- 5. Manejo acceso a tecnología ---\n",
        "    # Primero manejar nulos en las columnas booleanas\n",
        "    tech_cols = ['FAMI_TIENEINTERNET', 'FAMI_TIENECOMPUTADOR']\n",
        "    for col in tech_cols:\n",
        "        # Convertir a flotante manteniendo nulos\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        # Imputar nulos con la moda\n",
        "        mode_val = df[col].mode()[0]\n",
        "        df[col] = df[col].fillna(mode_val)\n",
        "\n",
        "    # Ahora crear la característica combinada\n",
        "    df['ACCESO_TECNOLOGIA'] = df['FAMI_TIENEINTERNET'] + df['FAMI_TIENECOMPUTADOR']\n",
        "\n",
        "    # --- 6. Optimización de one-hot encoding para matrícula ---\n",
        "    # Agrupar categorías\n",
        "    matricula_groups = {\n",
        "        'Menos de 500 mil': 'BAJA',\n",
        "        'Entre 500 mil y menos de 1 millón': 'BAJA',\n",
        "        'Entre 1 millón y menos de 2.5 millones': 'MEDIA',\n",
        "        'Entre 2.5 millones y menos de 4 millones': 'MEDIA_ALTA',\n",
        "        'Entre 4 millones y menos de 5.5 millones': 'ALTA',\n",
        "        'Entre 5.5 millones y menos de 7 millones': 'ALTA',\n",
        "        'Más de 7 millones': 'PREMIUM'\n",
        "    }\n",
        "\n",
        "    df['GRUPO_MATRICULA'] = df['ESTU_VALORMATRICULAUNIVERSIDAD'].map(matricula_groups).fillna('NO_PAGO')\n",
        "\n",
        "    # Aplicar one-hot a grupos consolidados\n",
        "    matricula_dummies = pd.get_dummies(df['GRUPO_MATRICULA'], prefix='MATRICULA')\n",
        "    df = pd.concat([df, matricula_dummies], axis=1)\n",
        "\n",
        "    # --- 7. Manejo de coeficientes ---\n",
        "    # Eliminar coeficientes irrelevantes\n",
        "    df = df.drop(['coef_3', 'coef_4'], axis=1, errors='ignore')\n",
        "\n",
        "    # Crear interacción entre coeficientes relevantes\n",
        "    df['COEF_INTERACCION'] = df['coef_1'] * df['coef_2']\n",
        "\n",
        "    # --- 8. Limpieza final ---\n",
        "    # Eliminar columnas redundantes\n",
        "    drop_cols = [\n",
        "        'ESTU_VALORMATRICULAUNIVERSIDAD', 'ESTU_HORASSEMANATRABAJA',\n",
        "        'GRUPO_MATRICULA', 'ESTU_PRGM_DEPARTAMENTO', 'PERIODO',\n",
        "        'FAMI_EDUCACIONPADRE', 'FAMI_EDUCACIONMADRE', 'FAMI_TIENELAVADORA',  # Se agrego FAMI_TIENELAVADORA y FAMI_TIENEAUTOMOVIL\n",
        "        'FAMI_TIENEAUTOMOVIL'\n",
        "    ]\n",
        "    df = df.drop(drop_cols, axis=1, errors='ignore')\n",
        "\n",
        "    # Codificación de variable objetivo\n",
        "    if not is_test and 'RENDIMIENTO_GLOBAL' in df.columns:\n",
        "        rendimiento_map = {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
        "        df['RENDIMIENTO_GLOBAL'] = df['RENDIMIENTO_GLOBAL'].map(rendimiento_map)\n",
        "\n",
        "    df['PROGRAMA_AGRUPADO'] = df['ESTU_PRGM_ACADEMICO'].apply(normalizar_programa)\n",
        "    df = df.drop('ESTU_PRGM_ACADEMICO', axis=1, errors='ignore')\n",
        "    df = df.dropna(subset=['PROGRAMA_AGRUPADO']).copy()  # Elimina registros con None\n",
        "\n",
        "    # Conservar solo programas con suficiente representación (top 15)\n",
        "    top_programas = df['PROGRAMA_AGRUPADO'].value_counts().nlargest(15).index\n",
        "    df['PROGRAMA_AGRUPADO'] = df['PROGRAMA_AGRUPADO'].apply(\n",
        "        lambda x: x if x in top_programas else 'OTROS'\n",
        "    )\n",
        "    \n",
        "    # One-Hot Encoding para mantener todos los registros\n",
        "    df = pd.get_dummies(df, columns=['PROGRAMA_AGRUPADO'], prefix='PROGRAMA')\n",
        "    print(df.select_dtypes(include='object').columns)\n",
        "    print(f\"Registros después de preprocesar: {len(df)}\")\n",
        "    \n",
        "    # Retornar ids\n",
        "    if is_test:\n",
        "        ids = df['ID'].copy()\n",
        "        return df, ids\n",
        "    else:\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lo unico que se cambio de aquí fue la eliminación de FAMI_TIENELAVADORA y FAMI_TIENEAUTOMOVIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3_gTEOHZibW"
      },
      "source": [
        "# Enfoque estructurado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxMB8mFpZusM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registros originales en test: 692500\n",
            "Index([], dtype='object')\n",
            "Registros después de preprocesar: 692500\n",
            "Registros originales en test: 692500\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar datos del dataset \n",
        "\n",
        "test_df = pd.read_csv('udea-ai-4-eng-20251-pruebas-saber-pro-colombia/test.csv')\n",
        "df = pd.read_csv(\"udea-ai-4-eng-20251-pruebas-saber-pro-colombia/train.csv\")\n",
        "\n",
        "clean_df = preprocess_data(df,is_test=False)\n",
        "\n",
        "# Separar características y objetivo\n",
        "X = clean_df.drop(['ID', 'RENDIMIENTO_GLOBAL'], axis=1)\n",
        "y = clean_df['RENDIMIENTO_GLOBAL']\n",
        "\n",
        "\n",
        "# Entrenar scaler solo con columnas numéricas\n",
        "numeric_cols = X.select_dtypes(include=['number']).columns\n",
        "scaler = StandardScaler().fit(X[numeric_cols])\n",
        "\n",
        "# Escalar datos de entrenamiento\n",
        "X_scaled = X.copy()\n",
        "X_scaled[numeric_cols] = scaler.transform(X[numeric_cols])\n",
        "\n",
        "\n",
        "# Dividir en train y validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGBC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Accuracy: 0.3950541516245487\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.53      0.46     34597\n",
            "           1       0.31      0.23      0.26     34455\n",
            "           2       0.30      0.22      0.26     34324\n",
            "           3       0.49      0.59      0.54     35124\n",
            "\n",
            "    accuracy                           0.40    138500\n",
            "   macro avg       0.38      0.39      0.38    138500\n",
            "weighted avg       0.38      0.40      0.38    138500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# A. Balanceo de clases (usando sample_weight)\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "sample_weights = np.array([class_weights[y] for y in y_train])\n",
        "\n",
        "# B. Hiperparámetros mejorados para XGBoost\n",
        "model = XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    eval_metric='mlogloss',\n",
        "    n_estimators=600,\n",
        "    max_depth=7,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.7,\n",
        "    reg_alpha=0.5,\n",
        "    reg_lambda=0.6,\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "# C. Entrenar con pesos\n",
        "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "y_pred_xgbc = model.predict(X_val)\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_val, y_pred_xgbc))\n",
        "print(classification_report(y_val, y_pred_xgbc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registros originales en test: 296786\n",
            "Index([], dtype='object')\n",
            "Registros después de preprocesar: 296786\n"
          ]
        }
      ],
      "source": [
        "# Cargar datos de test\n",
        "test_df = pd.read_csv('udea-ai-4-eng-20251-pruebas-saber-pro-colombia/test.csv')\n",
        "\n",
        "# Aplicar mismo preprocesamiento\n",
        "X_test_processed, test_ids = preprocess_data(test_df, is_test=True)  # Usar misma función de preprocesamiento\n",
        "\n",
        "\n",
        "# Escalar datos de test\n",
        "X_test_scaled = X_test_processed.copy()\n",
        "X_test_scaled[numeric_cols] = scaler.transform(X_test_processed[numeric_cols])\n",
        "\n",
        "X_test_scaled_final = X_test_scaled.drop('ID', axis=1)\n",
        "\n",
        "# Predecir\n",
        "preds = model.predict(X_test_scaled_final)\n",
        "label_map = {0:'bajo', 1:'medio-bajo', 2:'medio-alto', 3:'alto'}\n",
        "predicted_labels = [label_map[pred] for pred in preds]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear submission\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': predicted_labels\n",
        "})\n",
        "submission.to_csv('alternative_delta_solution.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
