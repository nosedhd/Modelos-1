{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za9ElGRUAk_j",
        "outputId": "52040ad9-d106-4ec9-edb1-b63fd7148f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aclaración\n",
        "\n",
        "\n",
        "La organización de carpetas y la descompresión se hizo de manera manual, lo unico que se mantuvo en codigo fue la descarga de la primera celda. Se pretende poner los notebooks en una carpeta anterior a la carpeta que se geenera despues de descomprimir la descarga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQEe-32oSExr"
      },
      "source": [
        "# Data Cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalizar_programa(texto):\n",
        "    if not isinstance(texto, str):\n",
        "        return 'OTROS'\n",
        "\n",
        "    texto = texto.lower()\n",
        "    palabras_clave = {\n",
        "        'admin': 'ADMINISTRACION',\n",
        "        'contad': 'CONTADURIA',\n",
        "        'ingenier': 'INGENIERIA',\n",
        "        'medic': 'MEDICINA',\n",
        "        'psicolog': 'PSICOLOGIA',\n",
        "        'derech': 'DERECHO',\n",
        "        'enfermer': 'ENFERMERIA',\n",
        "        'econom': 'ECONOMIA',\n",
        "        'arquitect': 'ARQUITECTURA'\n",
        "    }\n",
        "\n",
        "    for key, value in palabras_clave.items():\n",
        "        if key in texto:\n",
        "            return value\n",
        "\n",
        "    return 'OTROS'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def preprocess_data(df, is_test=False):\n",
        "\n",
        "    # print(f\"Registros originales en test: {len(df)}\")\n",
        "\n",
        "    # --- 1. Eliminación de columnas redundantes ---\n",
        "    df = df.drop(['FAMI_TIENEINTERNET.1', 'ESTU_PRIVADO_LIBERTAD'], axis=1, errors='ignore')\n",
        "\n",
        "    # --- 2. Conversión de variables booleanas con manejo de nulos mejorado ---\n",
        "    bool_map = {'Si': 1, 'No': 0}\n",
        "    bool_cols = ['FAMI_TIENEINTERNET', 'FAMI_TIENELAVADORA',\n",
        "             'FAMI_TIENEAUTOMOVIL', 'ESTU_PAGOMATRICULAPROPIO',\n",
        "             'FAMI_TIENECOMPUTADOR']\n",
        "\n",
        "    # Convertir a numérico y mantener nulos\n",
        "    for col in bool_cols:\n",
        "        df[col] = df[col].map(bool_map)\n",
        "\n",
        "    # --- 3. Procesamiento de estrato socioeconómico ---\n",
        "    # Extraer números de estrato y convertir a float\n",
        "    df['FAMI_ESTRATOVIVIENDA'] = (\n",
        "        df['FAMI_ESTRATOVIVIENDA']\n",
        "        .str.extract(r'(\\d+)')\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "    # Imputar con mediana (más robusto que moda)\n",
        "    median_estrato = df['FAMI_ESTRATOVIVIENDA'].median()\n",
        "    df['FAMI_ESTRATOVIVIENDA'] = df['FAMI_ESTRATOVIVIENDA'].fillna(median_estrato)\n",
        "\n",
        "    # Crear feature binaria para estratos bajos\n",
        "    df['ESTRATO_BAJO'] = (df['FAMI_ESTRATOVIVIENDA'] <= 2).astype(int)\n",
        "\n",
        "    # --- 4. Manejo de educación padres ---\n",
        "    edu_mapping = {\n",
        "        'Ninguno': 0,\n",
        "        'No sabe': 0,\n",
        "        'Primaria incompleta': 1,\n",
        "        'Primaria completa': 2,\n",
        "        'Secundaria (Bachillerato) incompleta': 3,\n",
        "        'Secundaria (Bachillerato) completa': 4,\n",
        "        'Técnica o tecnológica incompleta': 4.5,\n",
        "        'Técnica o tecnológica completa': 5,\n",
        "        'Universitaria incompleta': 5.5,\n",
        "        'Universitaria completa': 6,\n",
        "        'Postgrado': 7\n",
        "    }\n",
        "\n",
        "    df['EDUCACION_PADRE'] = df['FAMI_EDUCACIONPADRE'].map(edu_mapping).fillna(0)\n",
        "    df['EDUCACION_MADRE'] = df['FAMI_EDUCACIONMADRE'].map(edu_mapping).fillna(0)\n",
        "\n",
        "    # Crear característica combinada\n",
        "    df['EDUCACION_PADRES'] = (df['EDUCACION_PADRE'] + df['EDUCACION_MADRE']) / 2\n",
        "\n",
        "    # --- 5. Manejo acceso a tecnología ---\n",
        "    # Primero manejar nulos en las columnas booleanas\n",
        "    tech_cols = ['FAMI_TIENEINTERNET', 'FAMI_TIENECOMPUTADOR']\n",
        "    for col in tech_cols:\n",
        "        # Convertir a flotante manteniendo nulos\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        # Imputar nulos con la moda\n",
        "        mode_val = df[col].mode()[0]\n",
        "        df[col] = df[col].fillna(mode_val)\n",
        "\n",
        "    # Ahora crear la característica combinada\n",
        "    df['ACCESO_TECNOLOGIA'] = df['FAMI_TIENEINTERNET'] + df['FAMI_TIENECOMPUTADOR']\n",
        "\n",
        "    # --- 6. Optimización de one-hot encoding para matrícula ---\n",
        "    # Agrupar categorías\n",
        "    matricula_groups = {\n",
        "        'Menos de 500 mil': 'BAJA',\n",
        "        'Entre 500 mil y menos de 1 millón': 'BAJA',\n",
        "        'Entre 1 millón y menos de 2.5 millones': 'MEDIA',\n",
        "        'Entre 2.5 millones y menos de 4 millones': 'MEDIA_ALTA',\n",
        "        'Entre 4 millones y menos de 5.5 millones': 'ALTA',\n",
        "        'Entre 5.5 millones y menos de 7 millones': 'ALTA',\n",
        "        'Más de 7 millones': 'PREMIUM'\n",
        "    }\n",
        "\n",
        "    df['GRUPO_MATRICULA'] = df['ESTU_VALORMATRICULAUNIVERSIDAD'].map(matricula_groups).fillna('NO_PAGO')\n",
        "\n",
        "    # Aplicar one-hot a grupos consolidados\n",
        "    matricula_dummies = pd.get_dummies(df['GRUPO_MATRICULA'], prefix='MATRICULA')\n",
        "    df = pd.concat([df, matricula_dummies], axis=1)\n",
        "\n",
        "    # --- 7. Manejo de coeficientes ---\n",
        "    # Eliminar coeficientes irrelevantes\n",
        "    df = df.drop(['coef_3', 'coef_4'], axis=1, errors='ignore')\n",
        "\n",
        "    # Crear interacción entre coeficientes relevantes\n",
        "    df['COEF_INTERACCION'] = df['coef_1'] * df['coef_2']\n",
        "\n",
        "    # --- 8. Limpieza final ---\n",
        "    # Eliminar columnas redundantes\n",
        "    drop_cols = [\n",
        "        'ESTU_VALORMATRICULAUNIVERSIDAD', 'ESTU_HORASSEMANATRABAJA',\n",
        "        'GRUPO_MATRICULA', 'ESTU_PRGM_DEPARTAMENTO', 'PERIODO',  # Tambien se podria quitar tiene automovil y tiene lavadora, pero eso se hara más adelante.\n",
        "        'FAMI_EDUCACIONPADRE', 'FAMI_EDUCACIONMADRE'\n",
        "    ]\n",
        "    df = df.drop(drop_cols, axis=1, errors='ignore')\n",
        "\n",
        "    # Codificación de variable objetivo\n",
        "    if not is_test and 'RENDIMIENTO_GLOBAL' in df.columns:\n",
        "        rendimiento_map = {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
        "        df['RENDIMIENTO_GLOBAL'] = df['RENDIMIENTO_GLOBAL'].map(rendimiento_map)\n",
        "\n",
        "    df['PROGRAMA_AGRUPADO'] = df['ESTU_PRGM_ACADEMICO'].apply(normalizar_programa)\n",
        "    df = df.drop('ESTU_PRGM_ACADEMICO', axis=1, errors='ignore')\n",
        "    df = df.dropna(subset=['PROGRAMA_AGRUPADO']).copy()  # Elimina registros con None\n",
        "\n",
        "    # Conservar solo programas con suficiente representación (top 15)\n",
        "    top_programas = df['PROGRAMA_AGRUPADO'].value_counts().nlargest(15).index\n",
        "    df['PROGRAMA_AGRUPADO'] = df['PROGRAMA_AGRUPADO'].apply(\n",
        "        lambda x: x if x in top_programas else 'OTROS'\n",
        "    )\n",
        "    \n",
        "    # One-Hot Encoding para mantener todos los registros\n",
        "    df = pd.get_dummies(df, columns=['PROGRAMA_AGRUPADO'], prefix='PROGRAMA')\n",
        "    # print(df.select_dtypes(include='object').columns)\n",
        "    # print(f\"Registros después de preprocesar: {len(df)}\")\n",
        "    \n",
        "    if is_test:\n",
        "        ids = df['ID'].copy()\n",
        "        return df, ids\n",
        "    else:\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3_gTEOHZibW"
      },
      "source": [
        "# Enfoque estructurado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxMB8mFpZusM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registros originales en test: 692500\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar datos de test\n",
        "test_df = pd.read_csv('udea-ai-4-eng-20251-pruebas-saber-pro-colombia/test.csv')\n",
        "df = pd.read_csv(\"udea-ai-4-eng-20251-pruebas-saber-pro-colombia/train.csv\")\n",
        "\n",
        "clean_df = preprocess_data(df,is_test=False)\n",
        "\n",
        "# Separar características y objetivo\n",
        "X = clean_df.drop(['ID', 'RENDIMIENTO_GLOBAL'], axis=1)\n",
        "y = clean_df['RENDIMIENTO_GLOBAL']\n",
        "\n",
        "\n",
        "# Entrenar scaler solo con columnas numéricas\n",
        "numeric_cols = X.select_dtypes(include=['number']).columns\n",
        "scaler = StandardScaler().fit(X[numeric_cols])\n",
        "\n",
        "# Escalar datos de entrenamiento\n",
        "X_scaled = X.copy()\n",
        "X_scaled[numeric_cols] = scaler.transform(X[numeric_cols])\n",
        "\n",
        "\n",
        "# Dividir en train y validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 0.3879494584837545\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.50      0.44     34597\n",
            "           1       0.30      0.24      0.27     34455\n",
            "           2       0.30      0.22      0.26     34324\n",
            "           3       0.49      0.58      0.53     35124\n",
            "\n",
            "    accuracy                           0.39    138500\n",
            "   macro avg       0.37      0.39      0.38    138500\n",
            "weighted avg       0.37      0.39      0.38    138500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Modelo base\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=25,\n",
        "    min_samples_split=10,\n",
        "    class_weight='balanced_subsample',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluación\n",
        "y_pred_rf = rf.predict(X_val)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_val, y_pred_rf))\n",
        "print(classification_report(y_val, y_pred_rf))\n",
        "\n",
        "# Optimización con RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [200, 300, 400],\n",
        "    'max_depth': [20, 25, 30, None],\n",
        "    'min_samples_split': [5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf_search = RandomizedSearchCV(\n",
        "    rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_search.fit(X_train, y_train)\n",
        "\n",
        "# Mejor modelo\n",
        "best_rf = rf_search.best_estimator_\n",
        "y_pred_best_rf = best_rf.predict(X_val)\n",
        "print(\"Optimized RF Accuracy:\", accuracy_score(y_val, y_pred_best_rf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar datos de test\n",
        "test_df = pd.read_csv('udea-ai-4-eng-20251-pruebas-saber-pro-colombia/test.csv')\n",
        "\n",
        "# Aplicar mismo preprocesamiento\n",
        "X_test_processed, test_ids = preprocess_data(test_df, is_test=True)  # Usar misma función de preprocesamiento\n",
        "\n",
        "\n",
        "# Escalar datos de test\n",
        "X_test_scaled = X_test_processed.copy()\n",
        "X_test_scaled[numeric_cols] = scaler.transform(X_test_processed[numeric_cols])\n",
        "\n",
        "X_test_scaled_final = X_test_scaled.drop('ID', axis=1)\n",
        "\n",
        "# Predecir\n",
        "preds = best_rf.predict(X_test_scaled_final)\n",
        "label_map = {0:'bajo', 1:'medio-bajo', 2:'medio-alto', 3:'alto'}\n",
        "predicted_labels = [label_map[pred] for pred in preds]\n",
        "\n",
        "# Crear submission\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': predicted_labels\n",
        "})\n",
        "submission.to_csv('alternative_submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
